# path: README.md
# Proyecto IA – Detección de Objetos + Descripciones (YOLOS/DETR + BLIP)

Detecta objetos en imágenes/video/webcam y genera **descripciones** por objeto y una **descripción global**.  
Incluye CLI y scripts para Windows (PowerShell). Modo **lite** para equipos sin GPU.

## Requisitos
- Python 3.10–3.13
- Internet en la **primera ejecución** (descarga modelos desde Hugging Face).
- Windows PowerShell (o Bash en macOS/Linux).
- (Opcional) Docker.

## Estructura

```
proyecto/
├─ tools/describe\_objects.py
├─ scripts/setup\_and\_run.ps1      # Windows
├─ scripts/setup\_and\_run.sh       # macOS/Linux (opcional)
├─ requirements.txt
├─ tests/test\_describe\_objects.py
├─ Dockerfile                     # CPU
└─ README.md
````

# 0) Abre PowerShell en la carpeta donde EXTRAJISTE el ZIP
#    Ejemplo: C:\proyectoia   (evita Desktop/Downloads/OneDrive)

# 1) (Una sola vez) permite scripts para tu usuario
Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned

# 2) Desbloquea todos los archivos extraídos (clave si vino de Internet)
Get-ChildItem -Recurse . | Unblock-File

# 3) Crea venv e instala dependencias (sin tests la primera vez)
.\scripts\setup_and_run.ps1 setup -SkipTests

# 5) Ejecuta con tu imagen (primera vez descarga modelos)
python tools\describe_objects.py --input .\img\image.png --out .\out --lite --cpu --max-side 1280 --lang es
# 6) Abre resultados
start .\out\image_annotated.jpg
notepad .\out\image.json
